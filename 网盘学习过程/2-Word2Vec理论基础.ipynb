{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 词向量到2word2vec与相关应用\n",
    "## NLP常见任务\n",
    "- 自动摘要\n",
    "- 指代消解\n",
    "- 机器翻译\n",
    "- 词性标注\n",
    "- 分词(中文, 日文等)\n",
    "- 主题识别\n",
    "- 文本分类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLP处理方法\n",
    "- 传统: 基于规则\n",
    "- 现代: 基于统计机器学习\n",
    "    - HMM, CRF, SVM, LDA, CNN...\n",
    "    - \"规则\"隐含在模型参数里"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 此编码需要保证词的相似性\n",
    "Nearest words to frog:\n",
    "\n",
    "## 简单词/短语翻译\n",
    "- 向量空间分布的相似性\n",
    "\n",
    "## 向量空间子结构\n",
    "- 最终目标: 词向量表示作为机器学习, 特别是深度学习的输入和表示空间"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 在计算机中表示一个词\n",
    "Dict\n",
    "### 问题\n",
    "1. 不能分辨细节的区别\n",
    "2. 需要大量人为劳动\n",
    "3. 主观\n",
    "4. 无法发现新词\n",
    "5. 难以精确计算词之间的相似度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 离散表示: Bag of Words\n",
    "- 文档的向量表示可以直接将各词的词向量表示加和\n",
    "- 词权重 -- 词在文档中的顺序没有被考虑\n",
    "    - TF-IDF\n",
    "    - Binary weighting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 离散表示: Bi-gram和N-gram\n",
    "- 优点: 考虑了词的顺序\n",
    "- 缺点: 词表的膨胀\n",
    "## 语言模型\n",
    "- 一句话(词组合)出现的概率\n",
    "- Unigram/1-gram\n",
    "- Bi-gram/2-gram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 离散表示的问题\n",
    "- 无法衡量词向量之间的关系\n",
    "- 词表维度随着语料库增长膨胀\n",
    "- n-gram次序列随语料库膨胀更快\n",
    "- 数据稀疏问题"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 分布式表示(Distributed representation)\n",
    "- 用一个词附近的其他词来表示该词\n",
    "- 现代统计自然语言处理中最有创见的想法之一"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 共现矩阵(Cocurrence matrix)\n",
    "Word-Document的共现矩阵主要用于发现主体(topic), 用于主体模型, 如LSA(Latent Semantic Analysis)\n",
    "\n",
    "局域窗中的Word-Word共现矩阵可以挖掘语法和语义信息--是一个对称矩阵\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 存在的问题\n",
    "将共现矩阵行列作为词向量\n",
    "- 向量为数随着词典大小线性增长\n",
    "- 存贮整个词典的空间消耗非常大\n",
    "- 一些模型如文本分类模型会面临稀疏性问题\n",
    "- 模型会欠稳定\n",
    "\n",
    "## 解决方式\n",
    "构造低维稠密向量作为词的分布式表示(25-1000)维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SVD降维\n",
    "### SVD降维问题\n",
    "- 计算量大O(n^3)\n",
    "- 难以为词典中国新加入的词分配词向量\n",
    "- 与其他深度学习模型框架差异大"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NNLM(Neural Network Language model)\n",
    "- 直接从语言模型出发, 将模型最优化过程转化为求词向量表示的过程\n",
    "    - **目标函数:** $L(\\theta)=\\sum_{t}logP(w_t|w_{t-n+1},...w_{t-1})$\n",
    "- 使用了非对称的前向窗函数, 窗长度为n-1\n",
    "- 滑动窗口遍历整个语料求和, 计算量正比于语料库大小\n",
    "- 概率P满足归一化条件, 这样不同位置t处的概率才能相加, 即\n",
    "$$\\sum_{w\\in \\{vocabulary\\}}P(w|w_{t-n+1},...w_{t-1})=1$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NNLM结构\n",
    "![](https://cdn.jsdelivr.net/gh/Alephant6/PicBed/202206051617806.png)\n",
    "- (N-1)个前向词: one-hot表示\n",
    "- 采用线性映射将One-hot表示投影到稠密D维表示\n",
    "- 输出层: Softmax\n",
    "- 各层权重最优化: BP + SGD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NNLM的计算复杂度\n",
    "![](https://cdn.jsdelivr.net/gh/Alephant6/PicBed/202206051629363.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## word2vec: CBOW(连续词袋)\n",
    "![](https://cdn.jsdelivr.net/gh/Alephant6/PicBed/202206051631071.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CBOW: 层次Softmax\n",
    "![](https://cdn.jsdelivr.net/gh/Alephant6/PicBed/202206051633840.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}